{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用RNN做文本生成\n",
    "举个小小的例子，来看看LSTM是怎么玩的  \n",
    "我们这里不再用char级别，我们用word级别来做。  \n",
    "第一步，一样，先导入各种库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jinfan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们把文本读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91007\n",
      "[['the', 'project', 'gutenberg', 'ebook', ',', 'oysters', 'and', 'fish', ',', 'by', 'thomas', 'j', '.'], ['(', 'thomas', 'jefferson', ')', 'murrey', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'united', 'states', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.'], ['you', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'www.gutenberg.org', '.']]\n"
     ]
    }
   ],
   "source": [
    "raw_text = ''\n",
    "for file in os.listdir(\"./input/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        raw_text += open(\"./input/\"+file, errors='ignore').read() + '\\n\\n'\n",
    "# raw_text = open('../input/Winston_Churchil.txt').read()\n",
    "raw_text = raw_text.lower()\n",
    "sentensor = nltk.data.load('tokenizers/punkt/english.pickle')     \n",
    "sents = sentensor.tokenize(raw_text)\n",
    "corpus = []\n",
    "for sen in sents:\n",
    "    corpus.append(nltk.word_tokenize(sen))\n",
    "\n",
    "print(len(corpus))\n",
    "print(corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好，w2v乱炖："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(corpus, size=128, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.19270892,  0.12162855, -0.14810276, -0.01111651,  0.23072407,\n",
       "       -0.00512885, -0.22223479,  0.00355991,  0.75731725,  0.2982118 ,\n",
       "       -0.19129482,  0.03900472,  0.38711336,  0.22451423, -0.43874365,\n",
       "        0.2865509 , -0.17099372,  0.12289249,  0.7095651 , -0.23809838,\n",
       "       -0.12687337, -0.05366936, -0.23201181, -0.06480336, -0.6539293 ,\n",
       "       -0.36103758,  0.58957523, -0.0852538 , -0.16164061,  0.0413104 ,\n",
       "       -0.4863821 ,  0.8605279 , -0.24927779,  0.165787  ,  0.41577283,\n",
       "        0.41274425, -0.7770883 ,  0.2604721 , -0.42613626,  0.10138069,\n",
       "        0.3256224 , -0.11975811,  0.7702248 , -0.4822458 , -0.32087472,\n",
       "       -0.33407477, -0.29361582, -0.2618962 ,  0.18204357,  0.11883137,\n",
       "        0.30217448,  0.1596854 ,  0.40029874, -0.5480654 , -0.6952363 ,\n",
       "        0.78702265,  0.09458437, -0.02461374,  0.07881169,  0.48614752,\n",
       "       -0.11118302, -0.09023389, -0.21484718, -0.02474138, -0.18988189,\n",
       "       -0.2324448 , -0.12519315, -0.5420816 , -0.08502176,  0.23633495,\n",
       "        0.17344679,  0.21758752,  0.6762684 ,  0.11410828,  0.31824642,\n",
       "        0.02689226,  0.02327707, -0.00780605, -0.1850529 , -0.09133447,\n",
       "       -0.41078055,  0.26547745,  0.16315174,  0.23257814,  0.27154282,\n",
       "        0.21198802,  0.3610934 ,  0.04983062,  0.03404543, -0.38154963,\n",
       "       -0.43391278,  0.14851244, -0.2311258 ,  0.27543595,  0.45084327,\n",
       "       -0.25114787, -0.24451497, -0.2956067 , -0.53259045,  0.2230958 ,\n",
       "       -0.5056638 , -0.74523884, -0.17157765, -0.15624633,  0.01193307,\n",
       "       -0.50951916,  0.03811343, -0.04302321,  0.05971378, -0.19405395,\n",
       "        0.25829846,  0.04380593, -0.1604282 ,  1.1234909 , -0.29933184,\n",
       "       -0.46662638, -0.14994624,  0.49380317,  0.3875659 ,  0.06559952,\n",
       "        0.19199648,  0.06187318, -0.11434026,  0.40909892,  0.25226372,\n",
       "        0.17460485,  0.25993726, -0.10660443], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model['office']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，其实我们还是以之前的方式来处理我们的training data，把源数据变成一个长长的x，好让LSTM学会predict下一个单词："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2163807"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_input = [item for sublist in corpus for item in sublist]\n",
    "len(raw_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_input[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2111782"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_stream = []\n",
    "vocab = w2v_model.wv.vocab\n",
    "for word in raw_input:\n",
    "    if word in vocab:\n",
    "        text_stream.append(word)\n",
    "len(text_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们这里的文本预测就是，给了前面的单词以后，下一个单词是谁?  \n",
    "比如，hello from the other, 给出 side  \n",
    "## 构造训练测试集\n",
    "我们需要把我们的raw text变成可以用来训练的x,y:  \n",
    "x 是前置字母们 y 是后一个字母"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "seq_length = 10\n",
    "x = []\n",
    "y = []\n",
    "for i in range(0, len(text_stream) - seq_length):\n",
    "\n",
    "    given = text_stream[i:i + seq_length]\n",
    "    predict = text_stream[i + seq_length]\n",
    "    x.append(np.array([w2v_model[word] for word in given]))\n",
    "    y.append(w2v_model[predict])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看看我们做好的数据集的长相："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.29256192  0.06595486  0.02557228 ...  0.01049521 -0.31776536\n",
      "   0.27186963]\n",
      " [ 0.0057021   0.01761983  0.01972884 ...  0.01804212 -0.00952614\n",
      "   0.06724231]\n",
      " [-0.27348143  0.0164412   0.1176875  ...  0.456112   -0.98872805\n",
      "   0.96937704]\n",
      " ...\n",
      " [ 0.03812757  0.685519   -1.5037822  ... -0.5998845   0.764545\n",
      "  -0.3681679 ]\n",
      " [ 0.21473177  0.00915707 -0.31077555 ...  0.01241322  0.17599805\n",
      "  -0.4713305 ]\n",
      " [-0.05145789 -0.20518498  1.4385833  ... -1.5857631  -1.2260756\n",
      "  -1.7917078 ]]\n",
      "[-2.057292    1.4928908  -0.57667494  0.38965368 -0.45786396 -0.4384504\n",
      "  0.72420835  0.9672309  -1.983221    0.2218328  -0.35341883 -0.72874343\n",
      "  0.9389885   0.45287448  1.3768233   0.68907756 -1.9638562   1.0806258\n",
      " -0.18083096  0.5511084   0.63933957  0.6183507  -0.47244754  0.7616638\n",
      " -1.1673354   1.108943    0.38035122 -0.1658669   0.8285052   0.39267507\n",
      " -0.47407213  0.556484    1.2145134   0.09423742  0.04607335 -0.42886657\n",
      "  0.94338363 -1.0058573   0.491691   -0.01756302 -1.1016032  -0.6154638\n",
      "  0.611328   -1.3482203   0.8194129   0.27017143  0.1997277  -1.6445613\n",
      "  0.05553629  1.2837484   1.5763751  -0.48773795 -0.3112247  -0.588707\n",
      "  0.08267367  0.07105801 -1.8310748   0.7753389   0.12806165  0.5723125\n",
      "  1.7953591  -0.869775   -1.9744418   1.0810382   0.36237657  1.1619103\n",
      "  0.8956409  -0.05750535  1.0066736   0.3301158   0.24841611  0.71539485\n",
      " -1.2235371   0.38372973  0.22591057  0.54836094  0.19860102  2.9868555\n",
      " -1.5324107   0.04896513  1.7652501  -0.71946007 -1.6894504  -0.8923957\n",
      " -0.60601103 -0.45002714  1.4194615  -0.78349286  0.14495741  0.56900656\n",
      " -0.12889083 -0.176563   -0.2533946   1.6006945  -0.27284575 -0.36585352\n",
      " -1.5965025   0.30613014 -0.16184402 -1.0206617  -0.42196167 -0.7969248\n",
      "  0.40142825  0.81643194  2.1737566   0.12724131  0.18781401  1.2346461\n",
      " -1.2457815  -0.7832255  -1.2566762   0.12136602  0.03086709 -0.9662589\n",
      "  1.031258    1.5032256  -1.4549071  -0.71977323  1.8325111   0.47943574\n",
      "  0.08789074 -0.14869006 -0.05338855 -0.95997566  0.9553151  -0.28946817\n",
      "  0.7323719   0.11271273]\n"
     ]
    }
   ],
   "source": [
    "print(x[10])\n",
    "print(y[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2111772\n",
      "2111772\n",
      "10\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "print(len(x))\n",
    "print(len(y))\n",
    "print(len(x[12]))\n",
    "print(len(x[12][0]))\n",
    "print(len(y[12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.reshape(x, (-1, seq_length, 128))\n",
    "y = np.reshape(y, (-1,128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们做两件事：  \n",
    "我们已经有了一个input的数字表达（w2v），我们要把它变成LSTM需要的数组格式： [样本数，时间步伐，特征]  \n",
    "第二，对于output，我们直接用128维的输出  \n",
    "## 模型建造\n",
    "LSTM模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(256, input_shape=(10, 128), dropout=0.2, recurrent_dropout=0.2)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, dropout_W=0.2, dropout_U=0.2, input_shape=(seq_length, 128)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 跑模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2111772/2111772 [==============================] - 1593s 754us/step - loss: 0.7404\n",
      "Epoch 2/50\n",
      " 757760/2111772 [=========>....................] - ETA: 18:12 - loss: 0.7252"
     ]
    }
   ],
   "source": [
    "model.fit(x, y, nb_epoch=50, batch_size=4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来写个程序，看看我们训练出来的LSTM的效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next(input_array):\n",
    "    x = np.reshape(input_array, (-1,seq_length,128))\n",
    "    y = model.predict(x)\n",
    "    return y\n",
    "\n",
    "def string_to_index(raw_input):\n",
    "    raw_input = raw_input.lower()\n",
    "    input_stream = nltk.word_tokenize(raw_input)\n",
    "    res = []\n",
    "    for word in input_stream[(len(input_stream)-seq_length):]:\n",
    "        res.append(w2v_model[word])\n",
    "    return res\n",
    "\n",
    "def y_to_word(y):\n",
    "    word = w2v_model.most_similar(positive=y, topn=1)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_article(init, rounds=30):\n",
    "    in_string = init.lower()\n",
    "    for i in range(rounds):\n",
    "        n = y_to_word(predict_next(string_to_index(in_string)))\n",
    "        in_string += ' ' + n[0][0]\n",
    "    return in_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = 'Language Models allow us to measure how likely a sentence is, which is an important for Machine'\n",
    "article = generate_article(init)\n",
    "print(article)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
