# 概率论
**机器学习中对概率论的大量使用**
## 不确定性的来源：
### 1、被建模系统内在的随机性
### 2、不完全观测
### 3、不完全建模
## 概率：
### 1、频率派概率：直接与事件发生的频率相联系
### 2、贝叶斯概率：涉及到确定性水平
## 离散型变量和概率质量函数（PMF）
**概率质量函数同时作用于多个随机变量，是联合概率分布**
### 若一个函数P是随机变量x的PMF，则：
**1、P 的定义域必须是 x 所有可能状态的集合  
2、∀x ∈ x, 0 ≤ P (x) ≤ 1. 不可能发生的事件概率为 0，并且不存在比这概率更低 的状态。类似的，能够确保一定发生的事件概率为 1，而且不存在比这概率更 高的状态。  
3、∑P(x) = 1.我们把这条性质称之为 归一化的(normalized)。如果没有这条性质，当我们计算很多事件其中之一发生的概率时可能会得到大于 1 的概率。**  
## 连续型变量和概率密度函数（PDF）
### 如果一个函数 p 是概率密度函数，则：
**1、p 的定义域必须是 x 所有可能状态的集合。  
2、∀x ∈ x,p(x) ≥ 0. 注意，我们并不要求 p(x) ≤ 1  
3、∫ p(x)dx = 1**  
## 有时候，我们知道了一组变量的联合概率分布，但想要了解其中一个子集的概 率分布。这种定义在子集上的概率分布被称为 边缘概率分布
## 条件概率
### P(y=y|x=x)=$\frac{P(y=y,x=x)}{P(x=x)}$ , P (x = x) > 0
## 链式法则 P(a,b,c)=P(a|b,c)·P(b,c)=P(a|b,c)·P(b|c)·P(c)
## 独立性，两个随机变量x，y
### 若P(x,y)=P(x)·P(y),则x，y相互独立
## 条件独立性：三个随机变量x，y，z
### 若P(x,y|z)=P(x|z)·P(y|z)，则x，y条件独立
## 期望，方差，协方差
### 期望：$E_{x~p}[f(x)] = \sum_{x}P(x)f(x)$
### 方差: $Var(f(x)) = E[(f(x)-E[f(x)])^2]$
### 标准差：方差的算术平方根
### 协方差：在某种意义上给出两个变量线性相关性的强度以及这些变量的尺度
### Cov(f(x),g(y))=E[f(x)-E[f(x)] (g(y)-E[g(y)])]
### 相关系数：将每个变量的贡献归一化，为了只衡量变量相关性而不受各个尺度大小的影响
**1、因为两个变量如果相互独立那么它们的协方差为零，如果两个变量的协方差不为零那么它们一定是相关的  
2、两个变量如果协方差为零，它们之间一定没有线性关系。独立性比零协方差的要求更强，因为独立性还排除了非线性的关系。两个变量相互依赖但具有零协方差是可能的**  
### 协方差矩阵：对角元是方差
# 常用概率分布
## Bernonlli分布：单个二值随机变量的分布
### P(x=1) = a
### P(x=0) = 1-a
### P(x=x) = $a^{x}(1-a)^{1-x}$
### $E_{x}[x] = a$
### $Var_{x}(x) = a(1-a)$
## Mutinonlli分布（范畴分布）
**具有k个不同状态的单个离散型随机变量上的分布，其中k是一个有限值**
## 高斯分布（正态分布）
### $N(x;u,\sigma ^2) = \sqrt{\frac{1}{2\pi \sigma ^2}}exp(-\frac{1}{2\sigma ^2}(x-u)^2)$
**正态分布由两个参数控制，μ ∈ R 和 σ ∈ (0, ∞)。参数 μ 给出了中心峰值的坐标，这也是分布的均值:E[x] = μ。分布的标准差用 σ 表示，方差用 σ2 表示**  
**当我们要对概率密度函数求值时，我们需要对 σ 平方并且取倒数。当我们需要 经常对不同参数下的概率密度函数求值时，一种更高效的参数化分布的方式是使用 参数 β ∈ (0, ∞)，来控制分布的 精度(precision)(或方差的倒数)**  
**$N(x;u,\beta ^{-1}) = \sqrt{\frac{\beta }{2\pi}}exp(-\frac{1}{2}\beta (x-u)^2)$**
## 指数分布和Laplace分布
### 指数分布：在x=0点取得边界点$P(x;\lambda)=\lambda |_{x\geq 0} exp(\lambda x)$
### Laplace分布：允许我们在任意一点u处设置概率质量的峰值$Laplace(x;u;y) = \frac{1}{2y}exp(-\frac{\left | x-u \right |}{y})$
## Divac分布：$P(x)=\delta (x-u)$
## 经验分布: $P(x) = \frac{1}{m}\sum_{i=1}^{m}\delta (x-x^{(i)})$
## 混合分布：$P(x) = \sum_{i}P(c=i)P(x|c=i)$
# 常用函数的有用性质
## logistic sigmoid:
### $\sigma (x)=\frac{1}{1+exp(-x)}$
**作用：logistic sigmoid 函数通常用来产生 Bernoulli 分布中的参数 φ，因为它的范围是 (0, 1)，处在 φ 的有效取值范围内，sigmoid 函数 在变量取绝对值非常大的正值或负值时会出现 饱和(saturate)现象，意味着函数会 变得很平，并且对输入的微小改变会变得不敏感。**
## softplus函数
### $\varepsilon (x) = log(1+exp(x)) = log(1+e^x)$
### softplus函数可以用来产生正态分布的$\beta $和$\alpha $参数,因此它的范围是(0,inf)
## 重要性质
### $\sigma (x) = \frac{exp(x)}{exp(x) + exp(0)}$
### $\frac{d\sigma (x)}{dx} = \sigma (x)(1-\sigma (x))$
### $1-\sigma (x) = \sigma (-x)$
### $log\sigma (x) = -\varepsilon (-x)$
### $\frac{d\varepsilon (x)}{dx} = \sigma (x)$
### $\forall x(0,1)$ , $\sigma ^{-1}(x) = log(\frac{x}{1-x})$
### $\forall x>0$ , $\varepsilon ^{-1}(x) = log(exp(x)-1)$
### $\varepsilon (x) = \int_{-\infty }^{x}\sigma (y)dy$
### $\varepsilon (x)-\varepsilon (-x) = x$
### $\sigma ^{-1}(x)$被称为分对数
# 贝叶斯规则
## 已知P(y|x) , 计算P(x|y)
### 若知P(x)，可用贝叶斯规则
### $P(x|y) = \frac{P(x)P(y|x)}{P(y)}$
### 其中$P(y) = \sum_{x}P(y|x)P(x)$来计算
# 结构化概率模型
**机器学习的算法经常会涉及到在非常多的随机变量上的概率分布。通常，这些概 率分布涉及到的直接相互作用都是介于非常少的变量之间的。使用单个函数来描述 整个联合概率分布是非常低效的 (无论是计算上还是统计上)。**  
**我们可以把概率分布分解成许多因子的乘积形式，而不是使用单一的函数来表 示概率分布。例如，假设我们有三个随机变量 a, b 和 c，并且 a 影响 b 的取值，b 影 响 c 的取值，但是 a 和 c 在给定 b 时是条件独立的。我们可以把全部三个变量的概 率分布重新表示为两个变量的概率分布的连乘形式:**  
### p(a, b, c) = p(a)p(b | a)p(c | b).
**这种分解可以极大地减少用来描述一个分布的参数数量。每个因子使用的参数 数目是它的变量数目的指数倍。这意味着，如果我们能够找到一种使每个因子分布 具有更少变量的分解方法，我们就能极大地降低表示联合分布的成本。**  
**我们可以用图来描述这种分解。这里我们使用的是图论中的 ‘‘图’’ 的概念:由 一些可以通过边互相连接的顶点的集合构成。当我们用图来表示这种概率分布的分 解，我们把它称为 结构化概率模型(structured probabilistic model)或者 图模型
(graphical model)。**  
## 有向图 ：
**有向(directed)模型使用带有有向边的图，它们用条件概率分布来表示分解， 就像上面的例子。特别地，有向模型对于分布中的每一个随机变量 xi 都包含着一个 影响因子，这个组成 xi条件概率的影响因子被称为 xi 的父节点，记为 PaG(xi):**  
### $p(x) = \frac{1}{Z}\prod_{i}\phi ^{(i)}(C^{(i)})$
## 无向图 ：
**无向(undirected)模型使用带有无向边的图，它们将分解表示成一组函数;不 像有向模型那样，这些函数通常不是任何类型的概率分布。G 中任何满足两两之 间有边连接的顶点的集合被称为团。无向模型中的每个团 C(i) 都伴随着一个因子 φ(i)(C(i))。这些因子仅仅是函数，并不是概率分布。每个因子的输出都必须是非负的，但是并没有像概率分布中那样要求因子的和或者积分为 1。**
