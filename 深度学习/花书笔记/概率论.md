# 概率论
**机器学习中对概率论的大量使用**
## 不确定性的来源：
### 1、被建模系统内在的随机性
### 2、不完全观测
### 3、不完全建模
## 概率：
### 1、频率派概率：直接与事件发生的频率相联系
### 2、贝叶斯概率：涉及到确定性水平
## 离散型变量和概率质量函数（PMF）
**概率质量函数同时作用于多个随机变量，是联合概率分布**
### 若一个函数P是随机变量x的PMF，则：
**1、P 的定义域必须是 x 所有可能状态的集合  
2、∀x ∈ x, 0 ≤ P (x) ≤ 1. 不可能发生的事件概率为 0，并且不存在比这概率更低 的状态。类似的，能够确保一定发生的事件概率为 1，而且不存在比这概率更 高的状态。  
3、∑P(x) = 1.我们把这条性质称之为 归一化的(normalized)。如果没有这条性质，当我们计算很多事件其中之一发生的概率时可能会得到大于 1 的概率。**  
## 连续型变量和概率密度函数（PDF）
### 如果一个函数 p 是概率密度函数，则：
**1、p 的定义域必须是 x 所有可能状态的集合。  
2、∀x ∈ x,p(x) ≥ 0. 注意，我们并不要求 p(x) ≤ 1  
3、∫ p(x)dx = 1**  
## 有时候，我们知道了一组变量的联合概率分布，但想要了解其中一个子集的概 率分布。这种定义在子集上的概率分布被称为 边缘概率分布
## 条件概率
### P(y=y|x=x)=$\frac{P(y=y,x=x)}{P(x=x)}$ , P (x = x) > 0
## 链式法则 P(a,b,c)=P(a|b,c)·P(b,c)=P(a|b,c)·P(b|c)·P(c)
## 独立性，两个随机变量x，y
### 若P(x,y)=P(x)·P(y),则x，y相互独立
## 条件独立性：三个随机变量x，y，z
### 若P(x,y|z)=P(x|z)·P(y|z)，则x，y条件独立
## 期望，方差，协方差
### 期望：$E_{x~p}[f(x)] = \sum_{x}P(x)f(x)$
### 方差: $Var(f(x)) = E[(f(x)-E[f(x)])^2]$
### 标准差：方差的算术平方根
### 协方差：在某种意义上给出两个变量线性相关性的强度以及这些变量的尺度
### Cov(f(x),g(y))=E[f(x)-E[f(x)](g(y)-E[g(y)])]

