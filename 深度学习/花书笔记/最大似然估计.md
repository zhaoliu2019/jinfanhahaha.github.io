# 最大似然估计
## 不同模型中得到特定函数作为好的 估计，而不是猜测某些函数可能是好的估计
## 步骤分解 ：
**1、考虑一组含有 m 个样本的数据集 X = {x(1), . . . , x(m)}，独立地由未知的真实数
据生成分布 $p_{data}(x)$ 生成。令 $p_{model}(x; θ)$ 是一族由 θ 确定在相同空间上的概率分布。换言之，$p_{model}(x; θ)$
将任意输入 x 映射到实数来估计真实概率 pdata(x)。对 θ 的最大似然估计被定义为:$\theta_{ML}=argmax\prod_{i=1}^{m}p_{model}(x^{i};\theta )$**  
**2、多个概率的乘积会因很多原因不便于计算。将之转化为求和形式$theta_{ML}=argmax\sum_{i=1}^{m}logp_{model}(x^{i};\theta)$**  
**3、因为当我们重新缩放代价函数时 arg max 不会改变，我们可以除以 m 得到和训练数据经验分布 $p_{data}$ 相关的期望作为准则:
$argmaxE_{x∼p_{data}}logp_{model}(x;θ)$**  
**4、一种解释最大似然估计的观点是将它看作最小化训练集上的经验分布 $p_{data}$ 和模型分布之间的差异，两者之间的差异程度可以通过 KL 散度度量。KL 散度被定义为:$D_{KL}(p_{data}||p_{model})=E_{x~p_{data}}[logp_{data}(x)-logp_{model}(x)]$**

