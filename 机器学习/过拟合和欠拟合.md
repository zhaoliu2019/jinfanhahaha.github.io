# 过拟合和欠拟合
**过拟合：指在一个训练数据上表现很好，但在任何新数据的泛化能力却很差的模型。**  
**欠拟合：它产生的模型甚至在训练数据上都没有好的表现，尽管这通常暗示你的模型不够好，而要继续寻找改进的模型。**  
**太复杂的模型导致过拟合：最基本的方法包括使用不同的数据来测试模型，最简单的方法是划分数据集，例：用2/3的数据来训练模型，剩余的1/3来衡量模型的表现。**  
### 有些情况下，测试集好也不一定好。
**1、训练和测试数据集中的共有模式不能泛化到大型数据集上**  
**2、一个更大的问题，如果划分训练集和测试集的目的不仅仅是为了判断模型，也是为了在许多模型中进行选择，此时，尽管不是所有的模型都是过拟合的，但“选择在测试集上表现很好  
的模型”是一种元训练，会把测试集当作另一个训练集而运作，在这种情况下，应该把数据集划分为三部分，一个用来建立模型的训练集，一个在训练好的模型上进行选择验证集  
一个用来判断最终的模型的测试集。**  

## 降低‘过拟合’风险的方法
**1、从数据入手，获得更多的训练数据，使用更多的训练数据是解决过拟合问题的最有效手段，因为更多的样本能够让模型学习到更多更有效的手段，因为更多的样本能够让模型学习到更有效的特征，减少噪音的影响，当然，直接增加实验数据一般是很困难，但是可以通过一定的规则来扩充数据，比如在图像的分类问题上，可以通过图像的平移，旋转，缩放等方式扩充数据，更进一步的，可以使用生成对抗网络合成大量的新训练数据**  
**2、降低模型复杂度，在数据较小时，模型过于复杂是产生过拟合的主要因素，适当降低模型复杂度可以避免模型拟合过多的采样噪音。例：神经网络中减少网络层数，神经元个数，在决策树中降低树的深度，进行剪枝等**  
**3、正则化方法，给模型的参数加上一定的正则化约束，比如将权值的大小加入到损失函数中，以L2正则化为例：$C = C_{0} + \frac{\lambda }{2n}\sum_{i}w_{i}^2$**  
**这样，在优化原来目标函数$C_{0}$的时候，也能避免权值过大带来的过拟合风险**  
**4、集成学习方法，集成学习是把多个模型集成在一起来降低单一模型的过拟合风险，如Bagging方法**

## 降低‘欠拟合’风险的方法
**1、添加新特征，当特征不足或现有特征与样本标签相关性不强时，模型容易出现欠拟合，通过挖掘‘上下文特征’，‘ID类特征’，‘组合特征’等新的特征，往往能取得更好的效果，在深度学习中，有很多模型可以帮助完成特征工程，如因子分解机，梯度提升决策树，Deep-crossing等都可以成为丰富特征的方法**  
**2、增加模型复杂度，简单模型的学习能力较差，通过增加模型复杂度可以使模型拥有更强的拟合能力，例：在线性模型中添加高次项，在神经网络中增加网络层数或神经元个数等。**  
**3、减少正则化系数，正则化是用来防止过拟合的，但当模型出现欠拟合时，则需要针对性的减少正则化系数。**
